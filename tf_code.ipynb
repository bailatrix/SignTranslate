{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the structure described in the tutorial at\n",
    "# https://www.kaggle.com/paultimothymooney/interpret-sign-language-with-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import zlib\n",
    "import itertools\n",
    "import sklearn\n",
    "import itertools\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 86,  91,  89],\n",
       "         [ 89,  94,  92],\n",
       "         [ 89,  94,  92],\n",
       "         ...,\n",
       "         [ 23,  32,  45],\n",
       "         [ 20,  29,  42],\n",
       "         [ 17,  26,  39]],\n",
       "\n",
       "        [[ 87,  93,  88],\n",
       "         [ 90,  96,  91],\n",
       "         [ 89,  95,  90],\n",
       "         ...,\n",
       "         [ 23,  32,  45],\n",
       "         [ 17,  26,  39],\n",
       "         [ 12,  21,  34]],\n",
       "\n",
       "        [[ 89,  95,  90],\n",
       "         [ 91,  97,  92],\n",
       "         [ 90,  96,  91],\n",
       "         ...,\n",
       "         [ 25,  34,  47],\n",
       "         [ 18,  27,  40],\n",
       "         [ 11,  20,  33]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[136, 124, 112],\n",
       "         [132, 121, 107],\n",
       "         [137, 126, 112],\n",
       "         ...,\n",
       "         [104,  88,  81],\n",
       "         [108,  90,  83],\n",
       "         [109,  91,  84]],\n",
       "\n",
       "        [[135, 123, 111],\n",
       "         [135, 124, 110],\n",
       "         [137, 126, 112],\n",
       "         ...,\n",
       "         [166, 146, 129],\n",
       "         [166, 146, 129],\n",
       "         [168, 145, 129]],\n",
       "\n",
       "        [[132, 120, 108],\n",
       "         [137, 126, 112],\n",
       "         [135, 124, 110],\n",
       "         ...,\n",
       "         [183, 161, 136],\n",
       "         [182, 160, 135],\n",
       "         [181, 159, 134]]],\n",
       "\n",
       "\n",
       "       [[[ 87,  88,  84],\n",
       "         [ 89,  91,  85],\n",
       "         [ 91,  93,  87],\n",
       "         ...,\n",
       "         [ 22,  33,  37],\n",
       "         [ 35,  46,  50],\n",
       "         [ 65,  77,  79]],\n",
       "\n",
       "        [[ 88,  89,  85],\n",
       "         [ 90,  92,  86],\n",
       "         [ 92,  94,  88],\n",
       "         ...,\n",
       "         [  5,  16,  20],\n",
       "         [  6,  17,  21],\n",
       "         [ 21,  32,  36]],\n",
       "\n",
       "        [[ 88,  89,  85],\n",
       "         [ 90,  92,  86],\n",
       "         [ 92,  94,  88],\n",
       "         ...,\n",
       "         [  0,  10,  17],\n",
       "         [  0,   9,  13],\n",
       "         [  2,  13,  17]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[124, 110,  92],\n",
       "         [125, 111,  93],\n",
       "         [128, 114,  96],\n",
       "         ...,\n",
       "         [176, 155, 133],\n",
       "         [172, 154, 131],\n",
       "         [170, 152, 129]],\n",
       "\n",
       "        [[123, 109,  91],\n",
       "         [123, 109,  91],\n",
       "         [128, 114,  96],\n",
       "         ...,\n",
       "         [147, 120, 100],\n",
       "         [142, 115,  95],\n",
       "         [139, 111,  94]],\n",
       "\n",
       "        [[120, 108,  90],\n",
       "         [122, 108,  90],\n",
       "         [127, 113,  95],\n",
       "         ...,\n",
       "         [119,  85,  72],\n",
       "         [112,  80,  67],\n",
       "         [107,  75,  62]]],\n",
       "\n",
       "\n",
       "       [[[ 84,  91,  84],\n",
       "         [ 87,  94,  87],\n",
       "         [ 90,  97,  90],\n",
       "         ...,\n",
       "         [116, 126, 126],\n",
       "         [117, 129, 129],\n",
       "         [122, 134, 134]],\n",
       "\n",
       "        [[ 86,  93,  86],\n",
       "         [ 88,  95,  88],\n",
       "         [ 90,  97,  90],\n",
       "         ...,\n",
       "         [ 95, 107, 107],\n",
       "         [113, 125, 125],\n",
       "         [120, 132, 132]],\n",
       "\n",
       "        [[ 86,  93,  86],\n",
       "         [ 88,  95,  88],\n",
       "         [ 90,  97,  90],\n",
       "         ...,\n",
       "         [ 46,  58,  60],\n",
       "         [ 73,  85,  87],\n",
       "         [ 98, 110, 112]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[128, 113,  94],\n",
       "         [130, 115,  96],\n",
       "         [131, 117,  98],\n",
       "         ...,\n",
       "         [173, 159, 130],\n",
       "         [172, 159, 127],\n",
       "         [170, 159, 127]],\n",
       "\n",
       "        [[129, 114,  95],\n",
       "         [130, 115,  96],\n",
       "         [130, 116,  97],\n",
       "         ...,\n",
       "         [162, 139, 113],\n",
       "         [155, 132, 106],\n",
       "         [150, 127, 101]],\n",
       "\n",
       "        [[128, 114,  92],\n",
       "         [128, 113,  94],\n",
       "         [128, 114,  95],\n",
       "         ...,\n",
       "         [126,  94,  75],\n",
       "         [120,  88,  69],\n",
       "         [114,  82,  63]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[126, 133, 130],\n",
       "         [126, 133, 130],\n",
       "         [126, 131, 129],\n",
       "         ...,\n",
       "         [ 52,  78, 108],\n",
       "         [ 43,  69,  93],\n",
       "         [ 34,  57,  79]],\n",
       "\n",
       "        [[125, 132, 129],\n",
       "         [126, 133, 130],\n",
       "         [127, 132, 130],\n",
       "         ...,\n",
       "         [ 51,  79, 109],\n",
       "         [ 44,  69,  95],\n",
       "         [ 38,  61,  83]],\n",
       "\n",
       "        [[125, 132, 129],\n",
       "         [128, 135, 132],\n",
       "         [129, 134, 132],\n",
       "         ...,\n",
       "         [ 48,  76, 107],\n",
       "         [ 38,  65,  92],\n",
       "         [ 44,  68,  92]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[121, 116, 115],\n",
       "         [121, 116, 115],\n",
       "         [121, 116, 115],\n",
       "         ...,\n",
       "         [ 36,  54,  55],\n",
       "         [ 36,  54,  55],\n",
       "         [ 36,  54,  55]],\n",
       "\n",
       "        [[124, 119, 118],\n",
       "         [123, 118, 117],\n",
       "         [122, 117, 116],\n",
       "         ...,\n",
       "         [ 36,  54,  55],\n",
       "         [ 36,  54,  55],\n",
       "         [ 36,  54,  55]],\n",
       "\n",
       "        [[126, 121, 120],\n",
       "         [124, 119, 118],\n",
       "         [123, 118, 117],\n",
       "         ...,\n",
       "         [ 36,  54,  55],\n",
       "         [ 36,  54,  55],\n",
       "         [ 36,  54,  55]]],\n",
       "\n",
       "\n",
       "       [[[ 83,  89,  88],\n",
       "         [ 84,  90,  89],\n",
       "         [ 85,  91,  90],\n",
       "         ...,\n",
       "         [126, 133, 126],\n",
       "         [125, 132, 125],\n",
       "         [125, 132, 125]],\n",
       "\n",
       "        [[ 84,  90,  89],\n",
       "         [ 85,  91,  90],\n",
       "         [ 85,  91,  90],\n",
       "         ...,\n",
       "         [134, 137, 128],\n",
       "         [134, 137, 128],\n",
       "         [134, 137, 128]],\n",
       "\n",
       "        [[ 84,  90,  89],\n",
       "         [ 85,  91,  90],\n",
       "         [ 86,  93,  90],\n",
       "         ...,\n",
       "         [134, 135, 126],\n",
       "         [133, 134, 125],\n",
       "         [133, 134, 125]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[118, 109,  89],\n",
       "         [117, 107,  89],\n",
       "         [117, 106,  92],\n",
       "         ...,\n",
       "         [166, 151, 135],\n",
       "         [169, 154, 138],\n",
       "         [168, 155, 139]],\n",
       "\n",
       "        [[116, 107,  87],\n",
       "         [119, 109,  91],\n",
       "         [117, 106,  92],\n",
       "         ...,\n",
       "         [171, 157, 138],\n",
       "         [172, 158, 139],\n",
       "         [170, 159, 139]],\n",
       "\n",
       "        [[115, 106,  86],\n",
       "         [120, 110,  92],\n",
       "         [117, 106,  92],\n",
       "         ...,\n",
       "         [169, 156, 134],\n",
       "         [168, 155, 133],\n",
       "         [166, 156, 132]]],\n",
       "\n",
       "\n",
       "       [[[121, 134, 132],\n",
       "         [124, 135, 133],\n",
       "         [128, 136, 135],\n",
       "         ...,\n",
       "         [ 11,  37,  77],\n",
       "         [ 84, 114, 163],\n",
       "         [149, 179, 234]],\n",
       "\n",
       "        [[121, 134, 132],\n",
       "         [125, 136, 134],\n",
       "         [128, 136, 135],\n",
       "         ...,\n",
       "         [ 23,  49,  89],\n",
       "         [109, 139, 188],\n",
       "         [148, 177, 234]],\n",
       "\n",
       "        [[122, 135, 133],\n",
       "         [127, 138, 136],\n",
       "         [129, 137, 136],\n",
       "         ...,\n",
       "         [ 39,  64, 106],\n",
       "         [133, 162, 213],\n",
       "         [143, 173, 230]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[129, 123, 118],\n",
       "         [129, 123, 118],\n",
       "         [128, 122, 117],\n",
       "         ...,\n",
       "         [ 44,  62,  63],\n",
       "         [ 44,  62,  63],\n",
       "         [ 43,  61,  62]],\n",
       "\n",
       "        [[128, 122, 117],\n",
       "         [128, 122, 117],\n",
       "         [129, 123, 118],\n",
       "         ...,\n",
       "         [ 43,  61,  62],\n",
       "         [ 43,  61,  62],\n",
       "         [ 43,  61,  62]],\n",
       "\n",
       "        [[129, 123, 118],\n",
       "         [128, 122, 117],\n",
       "         [130, 124, 119],\n",
       "         ...,\n",
       "         [ 43,  61,  62],\n",
       "         [ 43,  61,  62],\n",
       "         [ 44,  62,  63]]]], dtype=uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageSize=50\n",
    "train_dir = \"./Dataset/train/\"\n",
    "test_dir =  \"./Dataset/test/\"\n",
    "import tqdm\n",
    "def get_data(folder):\n",
    "    \"\"\"\n",
    "    Load the data and labels from the given folder.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for folderName in os.listdir(train_dir):\n",
    "        if folderName == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            for filename in os.listdir(f'{train_dir}/{folderName}'):\n",
    "                if filename.startswith('A'):\n",
    "                    label = 0\n",
    "                elif filename.startswith('B'):\n",
    "                    label = 1\n",
    "                elif filename.startswith('C'):\n",
    "                    label = 2\n",
    "                elif filename.startswith('D'):\n",
    "                    label = 3\n",
    "                elif filename.startswith('E'):\n",
    "                    label = 4\n",
    "                elif filename.startswith('F'):\n",
    "                    label = 5\n",
    "                elif filename.startswith('G'):\n",
    "                    label = 6\n",
    "                elif filename.startswith('H'):\n",
    "                    label = 7\n",
    "                elif filename.startswith('I'):\n",
    "                    label = 8\n",
    "                elif filename.startswith('J'):\n",
    "                    label = 9\n",
    "                elif filename.startswith('K'):\n",
    "                    label = 10\n",
    "                elif filename.startswith('L'):\n",
    "                    label = 11\n",
    "                elif filename.startswith('M'):\n",
    "                    label = 12\n",
    "                elif filename.startswith('N'):\n",
    "                    label = 13\n",
    "                elif filename.startswith('O'):\n",
    "                    label = 14\n",
    "                elif filename.startswith('P'):\n",
    "                    label = 15\n",
    "                elif filename.startswith('Q'):\n",
    "                    label = 16\n",
    "                elif filename.startswith('R'):\n",
    "                    label = 17\n",
    "                elif filename.startswith('S'):\n",
    "                    label = 18\n",
    "                elif filename.startswith('T'):\n",
    "                    label = 19\n",
    "                elif filename.startswith('U'):\n",
    "                    label = 20\n",
    "                elif filename.startswith('V'):\n",
    "                    label = 21\n",
    "                elif filename.startswith('W'):\n",
    "                    label = 22\n",
    "                elif filename.startswith('X'):\n",
    "                    label = 23\n",
    "                elif filename.startswith('Y'):\n",
    "                    label = 24\n",
    "                elif filename.startswith('Z'):\n",
    "                    label = 25\n",
    "                    \n",
    "                img_file = cv2.imread(folder + folderName + '/' +filename)\n",
    "                if img_file is not None:\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        return X,y\n",
    "    \n",
    "X_train, y_train = get_data(train_dir) \n",
    "#X_test, y_test= get_data(test_dir) # Too few images\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2) \n",
    "\n",
    "# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "y_trainHot = tf.keras.utils.to_categorical(y_train, num_classes = 30)\n",
    "y_testHot = tf.keras.utils.to_categorical(y_test, num_classes = 30)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data to permit further subsampling\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_trainHot = shuffle(X_train, y_trainHot, random_state=13)\n",
    "X_test, y_testHot = shuffle(X_test, y_testHot, random_state=13)\n",
    "X_train = X_train[:30000]\n",
    "X_test = X_test[:30000]\n",
    "y_trainHot = y_trainHot[:30000]\n",
    "y_testHot = y_testHot[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data to permit further subsampling\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_trainHot = shuffle(X_train, y_trainHot, random_state=13)\n",
    "X_test, y_testHot = shuffle(X_test, y_testHot, random_state=13)\n",
    "X_train = X_train[:30000]\n",
    "X_test = X_test[:30000]\n",
    "y_trainHot = y_trainHot[:30000]\n",
    "y_testHot = y_testHot[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3c98cb6eb83a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mplotHistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "def plotHistogram(a):\n",
    "    \"\"\"\n",
    "    Plot histogram of RGB Pixel Intensities\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(a)\n",
    "    plt.axis('off')\n",
    "    histo = plt.subplot(1,2,2)\n",
    "    histo.set_ylabel('Count')\n",
    "    histo.set_xlabel('Pixel Intensity')\n",
    "    n_bins = 30\n",
    "    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n",
    "    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n",
    "    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\n",
    "plotHistogram(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multipleImages = glob('../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/A/**')\n",
    "def plotThreeImages(images):\n",
    "    r = random.sample(images, 3)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(cv2.imread(r[0]))\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(cv2.imread(r[1]))\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(cv2.imread(r[2]))\n",
    "    #;\n",
    "plotThreeImages(multipleImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multipleImages = glob('../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/B/**')\n",
    "def plotThreeImages(images):\n",
    "    r = random.sample(images, 3)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(cv2.imread(r[0]))\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(cv2.imread(r[1]))\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(cv2.imread(r[2])) \n",
    "plotThreeImages(multipleImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A\")\n",
    "multipleImages = glob('../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/A/**')\n",
    "i_ = 0\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for l in multipleImages[:25]:\n",
    "    im = cv2.imread(l)\n",
    "    im = cv2.resize(im, (128, 128)) \n",
    "    plt.subplot(5, 5, i_+1) #.set_title(l)\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
    "    i_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_characters = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'del', 27: 'nothing', 28: 'space', 29: 'other'}\n",
    "dict_characters=map_characters\n",
    "import seaborn as sns\n",
    "df = pd.DataFrame()\n",
    "df[\"labels\"]=y_train\n",
    "lab = df['labels']\n",
    "dist = lab.value_counts()\n",
    "sns.countplot(lab)\n",
    "print(dict_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions  Learning Curves and Confusion Matrix\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot_learning_curve(history):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./accuracy_curve.png')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./loss_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_characters1 = map_characters\n",
    "class_weight1 = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weight_path1 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weight_path2 = '../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pretrained_model_1 = VGG16(weights = weight_path1, include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "#pretrained_model_2 = InceptionV3(weights = weight_path2, include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "optimizer1 = keras.optimizers.Adam()\n",
    "optimizer2 = keras.optimizers.RMSprop(lr=0.0001)\n",
    "def pretrainedNetwork(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n",
    "    base_model = pretrained_model_1 # Topless\n",
    "    # Add top layer\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(numclasses, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    # Train top layer\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "    model.summary()\n",
    "    # Fit model\n",
    "    history = model.fit(xtrain,ytrain, epochs=numepochs, class_weight=classweight, validation_data=(xtest,ytest), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n",
    "    # Evaluate model\n",
    "    score = model.evaluate(xtest,ytest, verbose=0)\n",
    "    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n",
    "    y_pred = model.predict(xtest)\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(ytest,axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    plotKerasLearningCurve()\n",
    "    plt.show()\n",
    "    plot_learning_curve(history)\n",
    "    plt.show()\n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
    "    plt.show()\n",
    "    return model\n",
    "pretrainedNetwork(X_train, y_trainHot, X_test, y_testHot,pretrained_model_1,weight_path1,class_weight1,30,10,optimizer1,map_characters1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: (1) try using more than 30000 of the 87000 images; (2) try using larger images; (3) try using different network architectures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
